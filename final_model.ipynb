{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto Inteligencia Computacional - Proyecto 8 - ID 8a\n",
    "\n",
    "## Integrantes\n",
    "- Juan Pablo Contreras\n",
    "- Pascual Marcone\n",
    "\n",
    "## Ayudante\n",
    "- Sebastian Guzman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 12800\n",
      "Image shape: torch.Size([1, 21, 21])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "\n",
    "#system\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "#ai\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import src\n",
    "importlib.reload(src)\n",
    "\n",
    "import src.model.metrics as metrics\n",
    "import src.model.train as train\n",
    "import src.model.ae as ae\n",
    "import src.model.gau as gaussian\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stamps_dataset = pd.read_pickle('data/5stamps_dataset.pkl')\n",
    "dataset_1_21 = pd.read_pickle('data/stamp_dataset_21_new.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_labels(dataset, old_value, new_value):\n",
    "    for key in dataset.keys():\n",
    "        if old_value in dataset[key]:\n",
    "            dataset[key][new_value] = dataset[key].pop(old_value)\n",
    "\n",
    "rename_labels(stamps_dataset, 'labels', 'class')\n",
    "rename_labels(stamps_dataset, 'science', 'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(gaussian)\n",
    "\n",
    "# generate fake gaussian dataset\n",
    "num_samples = 15000\n",
    "image_size = 21\n",
    "border_margin = 4\n",
    "noise_level = 0.1\n",
    "brightness = 0.7\n",
    "\n",
    "gaussian_images = gaussian.generate_gaussian_dataset(num_samples, image_size, border_margin, noise_level, brightness)\n",
    "gaussian_dataset = TensorDataset(gaussian_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5stamps_dataset (MODIFICAR PARA DUAL CHANNEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_0 = torch.tensor(stamps_dataset['Train']['difference'], dtype=torch.float32)\n",
    "validation_dataset_0 = torch.tensor(stamps_dataset['Validation']['difference'], dtype=torch.float32)\n",
    "test_dataset_0 = torch.tensor(stamps_dataset['Test']['difference'], dtype=torch.float32)\n",
    "\n",
    "train_class_0 = torch.tensor(stamps_dataset['Train']['class'], dtype=torch.float32)\n",
    "validation_class_0 = torch.tensor(stamps_dataset['Validation']['class'], dtype=torch.float32)\n",
    "test_class_0 = torch.tensor(stamps_dataset['Test']['class'], dtype=torch.float32)\n",
    "\n",
    "#normalize between 0 and 1\n",
    "train_difference = (train_dataset_0 - train_dataset_0.min()) / (train_dataset_0.max() - train_dataset_0.min())\n",
    "validation_difference = (validation_dataset_0 - validation_dataset_0.min()) / (validation_dataset_0.max() - validation_dataset_0.min())\n",
    "test_difference = (test_dataset_0 - test_dataset_0.min()) / (test_dataset_0.max() - test_dataset_0.min())\n",
    "\n",
    "# Reshape the arrays to separate timestamps\n",
    "num_samples, num_photos, height, width = train_difference.shape\n",
    "reshaped_train_difference = train_difference.reshape(num_samples * num_photos, 1, height, width)\n",
    "reshaped_train_class = train_class_0.repeat_interleave(num_photos)\n",
    "\n",
    "num_samples, num_photos, height, width = validation_difference.shape\n",
    "reshaped_val_difference = validation_difference.reshape(validation_difference.shape[0] * num_photos, 1, height, width)\n",
    "reshaped_val_class = validation_class_0.repeat_interleave(num_photos)\n",
    "\n",
    "num_samples, num_photos, height, width = test_difference.shape\n",
    "reshaped_test_difference = test_difference.reshape(test_difference.shape[0] * num_photos, 1, height, width)\n",
    "reshaped_test_class = test_class_0.repeat_interleave(num_photos)\n",
    "\n",
    "train_dataset_0 = TensorDataset(reshaped_train_difference, reshaped_train_class)\n",
    "validation_dataset_0 = TensorDataset(reshaped_val_difference, reshaped_val_class)\n",
    "test_dataset_0 = TensorDataset(reshaped_test_difference, reshaped_test_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stamp_dataset_21_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_difference = torch.tensor(dataset_1_21['Train']['images'], dtype=torch.float32)\n",
    "validation_difference = torch.tensor(dataset_1_21['Validation']['images'], dtype=torch.float32)\n",
    "test_difference = torch.tensor(dataset_1_21['Test']['images'], dtype=torch.float32)\n",
    "\n",
    "train_class_1 = torch.tensor(dataset_1_21['Train']['class'], dtype=torch.float32)\n",
    "validation_class_1 = torch.tensor(dataset_1_21['Validation']['class'], dtype=torch.float32)\n",
    "test_class_1 = torch.tensor(dataset_1_21['Test']['class'], dtype=torch.float32)\n",
    "\n",
    "train_difference = (train_difference - train_difference.min()) / (train_difference.max() - train_difference.min())\n",
    "validation_difference = (validation_difference - validation_difference.min()) / (validation_difference.max() - validation_difference.min())\n",
    "test_difference = (test_difference - test_difference.min()) / (test_difference.max() - test_difference.min())\n",
    "\n",
    "\n",
    "# Seleccionar los canales 0 y 2\n",
    "train_difference_reshaped = train_difference[:, :, :, [0, 2]]\n",
    "validation_difference_reshaped = validation_difference[:, :, :, [0, 2]]\n",
    "test_difference_reshaped = test_difference[:, :, :, [0, 2]]\n",
    "\n",
    "# Permutar las dimensiones para que tengan la forma [batch_size, num_channels, height, width]\n",
    "train_difference_reshaped_perm = train_difference_reshaped.permute(0, 3, 1, 2)\n",
    "validation_difference_reshaped_perm = validation_difference_reshaped.permute(0, 3, 1, 2)\n",
    "test_difference_reshaped_perm = test_difference_reshaped.permute(0, 3, 1, 2)\n",
    "\n",
    "train_dataset_1 = TensorDataset(train_difference_reshaped_perm, train_class_1)\n",
    "validation_dataset_1 = TensorDataset(validation_difference_reshaped_perm, validation_class_1)\n",
    "test_dataset_1 = TensorDataset(test_difference_reshaped_perm, test_class_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ae)\n",
    "importlib.reload(train)\n",
    "importlib.reload(metrics)\n",
    "\n",
    "#static parameters\n",
    "max_epochs = 1000\n",
    "criterion = ae.loss_function\n",
    "batch_size = 100 #100\n",
    "lr = 0.333e-4 #propuesto en paper astorga\n",
    "\n",
    "early_stopping = 15\n",
    "use_gpu = True\n",
    "\n",
    "model_1_1 = ae.AE(latent_dim = 30, n_channels=2, name='with no augmentation')\n",
    "model_1_2 = ae.AE(latent_dim = 30, n_channels=2, name='with augmentation')\n",
    "model_1_3 = ae.AE(latent_dim = 30, n_channels=2, name='with augmentation and shuffling')\n",
    "\n",
    "curves_1_1, tiempo_1_1, mse_1_1 = train.train_model(model_1_1,\n",
    "                                            train_dataset_1,\n",
    "                                            validation_dataset_1,\n",
    "                                            test_dataset_1,\n",
    "                                            max_epochs=max_epochs,\n",
    "                                            criterion=criterion,\n",
    "                                            batch_size=batch_size,\n",
    "                                            lr=lr,\n",
    "                                            augmentation=False,\n",
    "                                            shuffle_augmentation=False,\n",
    "                                            early_stop=early_stopping,\n",
    "                                            use_gpu=use_gpu\n",
    "                                            )\n",
    "\n",
    "curves_1_2, tiempo_1_2, mse_1_2 = train.train_model(model_1_2,\n",
    "                                            train_dataset_1,\n",
    "                                            validation_dataset_1,\n",
    "                                            test_dataset_1,\n",
    "                                            max_epochs=max_epochs,\n",
    "                                            criterion=criterion,\n",
    "                                            batch_size=batch_size,\n",
    "                                            lr=lr,\n",
    "                                            augmentation=True,\n",
    "                                            shuffle_augmentation=False,\n",
    "                                            early_stop=early_stopping,\n",
    "                                            use_gpu=use_gpu\n",
    "                                            )\n",
    "\n",
    "curves_1_3, tiempo_1_3, mse_1_3 = train.train_model(model_1_3,\n",
    "                                            train_dataset_1,\n",
    "                                            validation_dataset_1,\n",
    "                                            test_dataset_1,\n",
    "                                            max_epochs=max_epochs,\n",
    "                                            criterion=criterion,\n",
    "                                            batch_size=batch_size,\n",
    "                                            lr=lr,\n",
    "                                            augmentation=True,\n",
    "                                            shuffle_augmentation=True,\n",
    "                                            early_stop=early_stopping,\n",
    "                                            use_gpu=use_gpu\n",
    "                                            )\n",
    "\n",
    "torch.save(model_1_1.state_dict(), 'models/model_1_1.pth')\n",
    "torch.save(model_1_2.state_dict(), 'models/model_1_2.pth')\n",
    "torch.save(model_1_3.state_dict(), 'models/model_1_3.pth')\n",
    "\n",
    "curves_1 = [curves_1_1, curves_1_2, curves_1_3]\n",
    "models_1 = [model_1_1, model_1_2, model_1_3]\n",
    "mse_1 = [mse_1_1, mse_1_2, mse_1_3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ae)\n",
    "importlib.reload(train)\n",
    "importlib.reload(metrics)\n",
    "\n",
    "#static parameters\n",
    "max_epochs = 1000\n",
    "criterion = ae.loss_function\n",
    "batch_size = 100 #100\n",
    "lr = 0.333e-4 #propuesto en paper astorga\n",
    "\n",
    "augmentation = True\n",
    "suffle = False\n",
    "early_stopping = 15\n",
    "use_gpu = True\n",
    "\n",
    "model_2_1 = ae.AE(latent_dim = 10, n_channels=2, name='latent dim 10')\n",
    "model_2_2 = ae.AE(latent_dim = 21, n_channels=2, name='latent dim 21')\n",
    "model_2_3 = ae.AE(latent_dim = 42, n_channels=2, name='latent dim 42')\n",
    "model_2_4 = ae.AE(latent_dim = 130, n_channels=2, name='latent dim 130')\n",
    "\n",
    "\n",
    "curves_2_1, tiempo_2_1, mse_2_1 = train.train_model(model_2_1,\n",
    "                                            train_dataset_1,\n",
    "                                            validation_dataset_1,\n",
    "                                            test_dataset_1,\n",
    "                                            max_epochs=max_epochs,\n",
    "                                            criterion=criterion,\n",
    "                                            batch_size=batch_size,\n",
    "                                            lr=lr,\n",
    "                                            augmentation=augmentation,\n",
    "                                            shuffle_augmentation=suffle,\n",
    "                                            early_stop=early_stopping,\n",
    "                                            use_gpu=use_gpu\n",
    "                                            )\n",
    "\n",
    "curves_2_2, tiempo_2_2, mse_2_2 = train.train_model(model_2_2,\n",
    "                                            train_dataset_1,\n",
    "                                            validation_dataset_1,\n",
    "                                            test_dataset_1,\n",
    "                                            max_epochs=max_epochs,\n",
    "                                            criterion=criterion,\n",
    "                                            batch_size=batch_size,\n",
    "                                            lr=lr,\n",
    "                                            augmentation=augmentation,\n",
    "                                            shuffle_augmentation=suffle,\n",
    "                                            early_stop=early_stopping,\n",
    "                                            use_gpu=use_gpu\n",
    "                                            )\n",
    "\n",
    "curves_2_3, tiempo_2_3, mse_2_3 = train.train_model(model_2_3,\n",
    "                                            train_dataset_1,\n",
    "                                            validation_dataset_1,\n",
    "                                            test_dataset_1,\n",
    "                                            max_epochs=max_epochs,\n",
    "                                            criterion=criterion,\n",
    "                                            batch_size=batch_size,\n",
    "                                            lr=lr,\n",
    "                                            augmentation=augmentation,\n",
    "                                            shuffle_augmentation=suffle,\n",
    "                                            early_stop=early_stopping,\n",
    "                                            use_gpu=use_gpu\n",
    "                                            )\n",
    "\n",
    "curves_2_4, tiempo_2_4, mse_2_4 = train.train_model(model_2_4,\n",
    "                                            train_dataset_1,\n",
    "                                            validation_dataset_1,\n",
    "                                            test_dataset_1,\n",
    "                                            max_epochs=max_epochs,\n",
    "                                            criterion=criterion,\n",
    "                                            batch_size=batch_size,\n",
    "                                            lr=lr,\n",
    "                                            augmentation=augmentation,\n",
    "                                            shuffle_augmentation=suffle,\n",
    "                                            early_stop=early_stopping,\n",
    "                                            use_gpu=use_gpu\n",
    "                                            )\n",
    "\n",
    "torch.save(model_2_1.state_dict(), 'models/model_2_1.pth')\n",
    "torch.save(model_2_2.state_dict(), 'models/model_2_2.pth')\n",
    "torch.save(model_2_3.state_dict(), 'models/model_2_3.pth')\n",
    "torch.save(model_2_4.state_dict(), 'models/model_2_4.pth')\n",
    "\n",
    "curves_2 = [curves_2_1, curves_2_2, curves_2_3, curves_2_4]\n",
    "models_2 = [model_2_1, model_2_2, model_2_3, model_2_4]\n",
    "mse_2 = [mse_2_1, mse_2_2, mse_2_3, mse_2_4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ae)\n",
    "importlib.reload(train)\n",
    "importlib.reload(metrics)\n",
    "\n",
    "#static parameters\n",
    "max_epochs = 1000\n",
    "criterion = ae.loss_function\n",
    "batch_size = 100 #100\n",
    "\n",
    "augmentation = True\n",
    "suffle = False\n",
    "early_stopping = 15\n",
    "use_gpu = True\n",
    "\n",
    "model_3_1 = ae.AE(latent_dim = 'definir', n_channels=2, name='with lr 0.333e-4')\n",
    "model_3_2 = ae.AE(latent_dim = 'definir', n_channels=2, name='latent dim 21')\n",
    "model_3_3 = ae.AE(latent_dim = 'definir', n_channels=2, name='latent dim 42')\n",
    "model_3_4 = ae.AE(latent_dim = 'definir', n_channels=2, name='latent dim 130')\n",
    "\n",
    "\n",
    "curves_3_1, tiempo_3_1, mse_3_1 = train.train_model(model_3_1,\n",
    "                                            train_dataset_1,\n",
    "                                            validation_dataset_1,\n",
    "                                            test_dataset_1,\n",
    "                                            max_epochs=max_epochs,\n",
    "                                            criterion=criterion,\n",
    "                                            batch_size=batch_size,\n",
    "                                            lr=0.333e-4,\n",
    "                                            augmentation=augmentation,\n",
    "                                            shuffle_augmentation=suffle,\n",
    "                                            early_stop=early_stopping,\n",
    "                                            use_gpu=use_gpu\n",
    "                                            )\n",
    "\n",
    "curves_3_2, tiempo_3_2, mse_3_2 = train.train_model(model_3_2,\n",
    "                                            train_dataset_1,\n",
    "                                            validation_dataset_1,\n",
    "                                            test_dataset_1,\n",
    "                                            max_epochs=max_epochs,\n",
    "                                            criterion=criterion,\n",
    "                                            batch_size=batch_size,\n",
    "                                            lr=0.333e-5,\n",
    "                                            augmentation=augmentation,\n",
    "                                            shuffle_augmentation=suffle,\n",
    "                                            early_stop=early_stopping,\n",
    "                                            use_gpu=use_gpu\n",
    "                                            )\n",
    "\n",
    "curves_3_3, tiempo_3_3, mse_3_3 = train.train_model(model_3_3,\n",
    "                                            train_dataset_1,\n",
    "                                            validation_dataset_1,\n",
    "                                            test_dataset_1,\n",
    "                                            max_epochs=max_epochs,\n",
    "                                            criterion=criterion,\n",
    "                                            batch_size=batch_size,\n",
    "                                            lr=0.333e-3,\n",
    "                                            augmentation=augmentation,\n",
    "                                            shuffle_augmentation=suffle,\n",
    "                                            early_stop=early_stopping,\n",
    "                                            use_gpu=use_gpu\n",
    "                                            )\n",
    "\n",
    "torch.save(model_3_1.state_dict(), 'models/model_3_1.pth')\n",
    "torch.save(model_3_2.state_dict(), 'models/model_3_2.pth')\n",
    "torch.save(model_3_3.state_dict(), 'models/model_3_3.pth')\n",
    "\n",
    "curves_3 = [curves_3_1, curves_3_2, curves_3_3]\n",
    "models_3 = [model_3_1, model_3_2, model_3_3]\n",
    "mse_3 = [mse_3_1, mse_3_2, mse_3_3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ae)\n",
    "importlib.reload(train)\n",
    "importlib.reload(metrics)\n",
    "\n",
    "#static parameters\n",
    "max_epochs = 1000\n",
    "criterion = ae.loss_function\n",
    "batch_size = 100 #100\n",
    "lr = 0.333e-4 #propuesto en paper astorga\n",
    "\n",
    "augmentation = True\n",
    "suffle = False\n",
    "early_stopping = 15\n",
    "use_gpu = True\n",
    "\n",
    "model_4_1 = ae.AE(latent_dim = 'definir', n_channels=2, name='trained with 5stamps_dataset')\n",
    "model_4_2 = ae.AE(latent_dim = 'definir', n_channels=2, name='trained with stamp_dataset_21_new')\n",
    "\n",
    "\n",
    "curves_4_1, tiempo_4_1, mse_4_1 = train.train_model(model_4_1,\n",
    "                                            train_dataset_0,\n",
    "                                            validation_dataset_0,\n",
    "                                            test_dataset_0,\n",
    "                                            max_epochs=max_epochs,\n",
    "                                            criterion=criterion,\n",
    "                                            batch_size=batch_size,\n",
    "                                            lr=lr,\n",
    "                                            augmentation=augmentation,\n",
    "                                            shuffle_augmentation=suffle,\n",
    "                                            early_stop=early_stopping,\n",
    "                                            use_gpu=use_gpu\n",
    "                                            )\n",
    "\n",
    "curves_4_2, tiempo_4_2, mse_4_2 = train.train_model(model_4_2,\n",
    "                                            train_dataset_1,\n",
    "                                            validation_dataset_1,\n",
    "                                            test_dataset_1,\n",
    "                                            max_epochs=max_epochs,\n",
    "                                            criterion=criterion,\n",
    "                                            batch_size=batch_size,\n",
    "                                            lr=lr,\n",
    "                                            augmentation=augmentation,\n",
    "                                            shuffle_augmentation=suffle,\n",
    "                                            early_stop=early_stopping,\n",
    "                                            use_gpu=use_gpu\n",
    "                                            )\n",
    "\n",
    "torch.save(model_4_1.state_dict(), 'models/model_4_1.pth')\n",
    "torch.save(model_4_2.state_dict(), 'models/model_4_2.pth')\n",
    "\n",
    "curves_4 = [curves_4_1, curves_4_2]\n",
    "models_4 = [model_4_1, model_4_2]\n",
    "mse_4 = [mse_4_1, mse_4_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Probing Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_1.eval()\n",
    "model_1_2.eval()\n",
    "model_1_3.eval()\n",
    "\n",
    "z_train_1_1 = model_1_1.only_encoder(train_difference_reshaped_perm).detach()\n",
    "z_train_1_2 = model_1_2.only_encoder(train_difference_reshaped_perm).detach()\n",
    "z_train_1_3 = model_1_3.only_encoder(train_difference_reshaped_perm).detach()\n",
    "\n",
    "z_train_label = train_class_1.detach()\n",
    "train_features_1_1 = TensorDataset(z_train_1_1, z_train_label)\n",
    "train\n",
    "\n",
    "z_val = model_full.only_encoder(validation_difference_reshaped_perm).detach()\n",
    "z_val_label = validation_class.detach()\n",
    "val_dataset_features = TensorDataset(z_val, z_val_label)\n",
    "\n",
    "z_test = model_full.only_encoder(test_difference_reshaped_perm).detach()\n",
    "z_test_label = test_class.detach()\n",
    "test_dataset_features = TensorDataset(z_test, z_test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "\n",
    "#umap \n",
    "n_neighbors = 15\n",
    "min_dist = 0.1\n",
    "metric = 'euclidean'\n",
    "norm = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning curves + mse\n",
    "metrics.show_curves(curves_1, models_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent space umap\n",
    "metrics.plot_umap(models_1, test_dataset_1, test_class_1, n_neighbors, min_dist, metric, norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear probing umap + confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruction examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning curves + mse\n",
    "metrics.show_curves(curves_2, models_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent space umap\n",
    "metrics.plot_umap(models_2, test_dataset_1, test_class_1, n_neighbors, min_dist, metric, norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear probing umap + confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruction examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning curves + mse\n",
    "metrics.show_curves(curves_3, models_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent space umap\n",
    "metrics.plot_umap(models_3, test_dataset_1, test_class_1, n_neighbors, min_dist, metric, norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear probing umap + confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruction examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning curves + mse\n",
    "metrics.show_curves(curves_4, models_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent space umap\n",
    "metrics.plot_umap(models_4, test_dataset_0, test_class_0, n_neighbors, min_dist, metric, norm)\n",
    "metrics.plot_umap(models_4, test_dataset_1, test_class_1, n_neighbors, min_dist, metric, norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear probing umap + confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruction examples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inteli_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
