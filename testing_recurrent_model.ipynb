{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "\n",
    "#system\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "#ai\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import src\n",
    "importlib.reload(src)\n",
    "\n",
    "import src.utils.metrics as metrics\n",
    "import src.model.train_recurrent as train_recurrent\n",
    "import src.model.ae as ae\n",
    "import src.model.ae_recurrente as ae_recurrente\n",
    "import src.utils.gau as gaussian\n",
    "import src.probing.linear_probing as lp\n",
    "import src.utils.plots as plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "stamps_dataset = pd.read_pickle('data/5stamps_dataset.pkl')\n",
    "#dataset_1_21 = pd.read_pickle('data/stamp_dataset_21_new.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_labels(dataset, old_value, new_value):\n",
    "    for key in dataset.keys():\n",
    "        if old_value in dataset[key]:\n",
    "            dataset[key][new_value] = dataset[key].pop(old_value)\n",
    "\n",
    "rename_labels(stamps_dataset, 'labels', 'class')\n",
    "rename_labels(stamps_dataset, 'science', 'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([123227, 5, 3, 21, 21])\n",
      "torch.Size([600, 5, 3, 21, 21])\n",
      "torch.Size([600, 5, 3, 21, 21])\n"
     ]
    }
   ],
   "source": [
    "train_template = torch.tensor(stamps_dataset['Train']['template'], dtype=torch.float32)\n",
    "validation_template = torch.tensor(stamps_dataset['Validation']['template'], dtype=torch.float32)\n",
    "test_template = torch.tensor(stamps_dataset['Test']['template'], dtype=torch.float32)\n",
    "\n",
    "train_difference = torch.tensor(stamps_dataset['Train']['difference'], dtype=torch.float32)\n",
    "validation_difference = torch.tensor(stamps_dataset['Validation']['difference'], dtype=torch.float32)\n",
    "test_difference = torch.tensor(stamps_dataset['Test']['difference'], dtype=torch.float32)\n",
    "\n",
    "train_image = torch.tensor(stamps_dataset['Train']['images'], dtype=torch.float32)\n",
    "validation_image = torch.tensor(stamps_dataset['Validation']['images'], dtype=torch.float32)\n",
    "test_image = torch.tensor(stamps_dataset['Test']['images'], dtype=torch.float32)\n",
    "\n",
    "train_class_0 = torch.tensor(stamps_dataset['Train']['class'], dtype=torch.float32)\n",
    "validation_class_0 = torch.tensor(stamps_dataset['Validation']['class'], dtype=torch.float32)\n",
    "test_class_0 = torch.tensor(stamps_dataset['Test']['class'], dtype=torch.float32)\n",
    "\n",
    "train_template = train_template.unsqueeze(1).repeat(1, 5, 1, 1)\n",
    "validation_template = validation_template.unsqueeze(1).repeat(1, 5, 1, 1)\n",
    "test_template = test_template.unsqueeze(1).repeat(1, 5, 1, 1)\n",
    "\n",
    "\n",
    "train_dataset = torch.stack((train_template, train_image, train_difference), dim=3  )\n",
    "validation_dataset = torch.stack((validation_template, validation_difference, validation_difference), dim=3)\n",
    "test_dataset = torch.stack((test_template, test_image, test_difference), dim=3)\n",
    "\n",
    "train_template = train_template.unsqueeze(2)  # (samples, 5, 1, 21, 21)\n",
    "train_image = train_image.unsqueeze(2)        \n",
    "train_difference = train_difference.unsqueeze(2)  \n",
    "\n",
    "validation_template = validation_template.unsqueeze(2)\n",
    "validation_image = validation_image.unsqueeze(2)\n",
    "validation_difference = validation_difference.unsqueeze(2)\n",
    "\n",
    "test_template = test_template.unsqueeze(2)\n",
    "test_image = test_image.unsqueeze(2)\n",
    "test_difference = test_difference.unsqueeze(2)\n",
    "\n",
    "# Apilar los tensores a lo largo de la dimensiÃ³n correcta\n",
    "train_dataset = torch.cat((train_template, train_image, train_difference), dim=2)\n",
    "validation_dataset = torch.cat((validation_template, validation_image, validation_difference), dim=2)\n",
    "test_dataset = torch.cat((test_template, test_image, test_difference), dim=2)\n",
    "\n",
    "# Crear los conjuntos de datos\n",
    "train_dataset = TensorDataset(train_dataset, train_class_0)\n",
    "validation_dataset = TensorDataset(validation_dataset, validation_class_0)\n",
    "test_dataset = TensorDataset(test_dataset, test_class_0)\n",
    "\n",
    "# Verificar las dimensiones de los conjuntos de datos\n",
    "print(train_dataset.tensors[0].shape)  # (samples, 5, 3, 21, 21)\n",
    "print(validation_dataset.tensors[0].shape)\n",
    "print(test_dataset.tensors[0].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training ...\n",
      "torch.Size([150, 5, 3, 21, 21])\n",
      "x torch.Size([750, 3, 21, 21])\n",
      "z torch.Size([150, 5, 21])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juanpablo/universidad/proyecto/ZTF_alert_8a/src/model/ae.py:86: UserWarning: Using a target size (torch.Size([150, 5, 3, 21, 21])) that is different to the input size (torch.Size([150, 3, 21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  recon_loss = F.mse_loss(recon_x, x, reduction='mean')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (150) must match the size of tensor b (5) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[94], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m15\u001b[39m\n\u001b[1;32m     24\u001b[0m use_gpu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m curves_2_0, tiempo_2_0, mse_2_0 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_recurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mvalidation_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43maugmentation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugmentation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mshuffle_augmentation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43muse_gpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_gpu\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/universidad/proyecto/ZTF_alert_8a/src/model/train_recurrent.py:151\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dataset, val_dataset, test_dataset, max_epochs, criterion, batch_size, lr, augmentation, shuffle_augmentation, early_stop, use_gpu)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28mprint\u001b[39m(diff\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    149\u001b[0m reconstruction \u001b[38;5;241m=\u001b[39m model(diff)\n\u001b[0;32m--> 151\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreconstruction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiff\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    152\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    153\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/universidad/proyecto/ZTF_alert_8a/src/model/ae.py:86\u001b[0m, in \u001b[0;36mloss_function\u001b[0;34m(recon_x, x)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_function\u001b[39m(recon_x, x):\n\u001b[0;32m---> 86\u001b[0m     recon_loss \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecon_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m recon_loss\n",
      "File \u001b[0;32m~/miniforge3/envs/inteli/lib/python3.12/site-packages/torch/nn/functional.py:3383\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3381\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3383\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mmse_loss(expanded_input, expanded_target, _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction))\n",
      "File \u001b[0;32m~/miniforge3/envs/inteli/lib/python3.12/site-packages/torch/functional.py:77\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tensors):\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[38;5;241m*\u001b[39mtensors)\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (150) must match the size of tensor b (5) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "importlib.reload(ae_recurrente)\n",
    "importlib.reload(train_recurrent)\n",
    "importlib.reload(metrics)\n",
    "\n",
    "\n",
    "\n",
    "model = ae_recurrente.AE_recurrent(latent_dim=21,\n",
    "                                    n_channels=3,\n",
    "                                    sequence_length=5,\n",
    "                                    hidden_dim=64,\n",
    "                                    num_layers=1,\n",
    "                                    name='AE_Recurrente_test')\n",
    "\n",
    "\n",
    "#static parameters\n",
    "max_epochs = 50\n",
    "criterion = ae.loss_function\n",
    "batch_size = 150 #100\n",
    "lr = 1.665e-4\n",
    "\n",
    "augmentation = False\n",
    "suffle = False\n",
    "early_stopping = 15\n",
    "use_gpu = False\n",
    "\n",
    "curves_2_0, tiempo_2_0, mse_2_0 = train_recurrent.train_model(model,\n",
    "                                            train_dataset,\n",
    "                                            validation_dataset,\n",
    "                                            test_dataset,\n",
    "                                            max_epochs=max_epochs,\n",
    "                                            criterion=criterion,\n",
    "                                            batch_size=batch_size,\n",
    "                                            lr=lr,\n",
    "                                            augmentation=augmentation,\n",
    "                                            shuffle_augmentation=suffle,\n",
    "                                            early_stop=early_stopping,\n",
    "                                            use_gpu=use_gpu)\n",
    "\n",
    "                                    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inteli",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
