{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1000)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./mnist\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:01<00:00, 9053167.31it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./mnist\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1000)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./mnist\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 242953.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./mnist\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1000)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./mnist\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 2051460.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./mnist\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1000)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./mnist\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./mnist\\MNIST\\raw\n",
      "\n",
      "El dataset de entrenamiento completo tiene: 55000 elementos.\n",
      "El dataset de validación tiene: 5000 elementos.\n",
      "El dataset de test tiene: 10000 elementos.\n",
      "\n",
      "Primer ejemplo obtenido del dataset:\n",
      "Tensor de tamaño: torch.Size([784]) con valor mínimo: 0.0 y máximo: 1.0\n",
      "Clase: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Dígito escogido para clasificar\n",
    "chosen_digit = 8\n",
    "\n",
    "# Se define una transformación para las imágenes (La primera transforma las imágenes a tensor y la segunda aplana los tensores en vectores)\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Lambda(lambda t: t.flatten()),\n",
    "])\n",
    "\n",
    "# Se define una transformación para los labels. Esta toma cada label y los transforma a 1 y 0,\n",
    "# donde 1 representa que el dígito es igual al dígito escogido (en este caso 8) y 0 representa que es otro dígito.\n",
    "target_transform = torchvision.transforms.Lambda(lambda label: 1 if label == chosen_digit else 0)\n",
    "\n",
    "# Se descargan los datasets de train y test de mnist y se transforman\n",
    "root_dataset_dir = \"./mnist\"\n",
    "\n",
    "train_mnist_dataset = torchvision.datasets.MNIST(\n",
    "    root=root_dataset_dir,\n",
    "    train=True,\n",
    "    transform=transform, # Acá definimos la transformación a las imágenes\n",
    "    target_transform=target_transform, # Acá definimos la transformación a los labels\n",
    "    download=True\n",
    ")\n",
    "test_mnist_dataset = torchvision.datasets.MNIST(\n",
    "    root=root_dataset_dir,\n",
    "    train=False,\n",
    "    transform=transform, # Acá definimos la transformación a las imágenes\n",
    "    target_transform=target_transform, # Acá definimos la transformación a los labels\n",
    "    download=True\n",
    ")\n",
    "\n",
    "# Del dataset de entrenamieno obtenemos una porción que utilizaremos como dataset de validación\n",
    "# Sabemos que son 60000 datos totales del dataset original de entrenamiento y 10000 de test.\n",
    "# Por lo tanto tomamos 10000 datos del dataset de entrenamiento y los utilizamos como validación (eliminándolos del dataset de entrenamiento)\n",
    "train_size = 55000\n",
    "val_size = len(train_mnist_dataset) - train_size\n",
    "train_mnist_dataset, val_mnist_dataset = torch.utils.data.random_split(train_mnist_dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "print(f\"El dataset de entrenamiento completo tiene: {len(train_mnist_dataset)} elementos.\")\n",
    "print(f\"El dataset de validación tiene: {len(val_mnist_dataset)} elementos.\")\n",
    "print(f\"El dataset de test tiene: {len(test_mnist_dataset)} elementos.\")\n",
    "\n",
    "print()\n",
    "\n",
    "x, y = train_mnist_dataset[0]\n",
    "print(f\"Primer ejemplo obtenido del dataset:\")\n",
    "print(f\"Tensor de tamaño: {x.shape} con valor mínimo: {x.min()} y máximo: {x.max()}\")\n",
    "print(\"Clase:\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_dataset(dataset):\n",
    "    data_tuples = [(x, y) for (x, y) in dataset]  # Separamos el dataset en X, y\n",
    "    X = torch.stack([t[0] for t in data_tuples])\n",
    "    y = torch.tensor([t[1] for t in data_tuples])\n",
    "\n",
    "    final_X = X.float()\n",
    "    final_y = y\n",
    "\n",
    "    final_dataset = torch.utils.data.TensorDataset(\n",
    "        final_X,\n",
    "        final_y,\n",
    "    )\n",
    "\n",
    "    return final_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanceando dataset de entrenamiento.\n",
      "\n",
      "Balanceando dataset de validación.\n",
      "\n",
      "Balanceando dataset de test.\n"
     ]
    }
   ],
   "source": [
    "print(\"Balanceando dataset de entrenamiento.\")\n",
    "train_mnist_dataset = balance_dataset(train_mnist_dataset)\n",
    "print()\n",
    "\n",
    "print(\"Balanceando dataset de validación.\")\n",
    "val_mnist_dataset = balance_dataset(val_mnist_dataset)\n",
    "print()\n",
    "\n",
    "print(\"Balanceando dataset de test.\")\n",
    "test_mnist_dataset = balance_dataset(test_mnist_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mnist_dataset = torch.utils.data.TensorDataset(\n",
    "    train_mnist_dataset.tensors[0].view(-1, 1, 28, 28),\n",
    "    train_mnist_dataset.tensors[1]\n",
    ")\n",
    "\n",
    "val_mnist_dataset = torch.utils.data.TensorDataset(\n",
    "    val_mnist_dataset.tensors[0].view(-1, 1, 28, 28),\n",
    "    val_mnist_dataset.tensors[1]\n",
    ")\n",
    "\n",
    "test_mnist_dataset = torch.utils.data.TensorDataset(\n",
    "    test_mnist_dataset.tensors[0].view(-1, 1, 28, 28),\n",
    "    test_mnist_dataset.tensors[1]\n",
    ")\n",
    "\n",
    "train_mnist_dataset = torch.utils.data.TensorDataset(\n",
    "    torch.nn.functional.interpolate(train_mnist_dataset.tensors[0], size=(21, 21)),\n",
    "    train_mnist_dataset.tensors[1]\n",
    ")\n",
    "\n",
    "val_mnist_dataset = torch.utils.data.TensorDataset(\n",
    "    torch.nn.functional.interpolate(val_mnist_dataset.tensors[0], size=(21, 21)),\n",
    "    val_mnist_dataset.tensors[1]\n",
    ")\n",
    "\n",
    "test_mnist_dataset = torch.utils.data.TensorDataset(\n",
    "    torch.nn.functional.interpolate(test_mnist_dataset.tensors[0], size=(21, 21)),\n",
    "    test_mnist_dataset.tensors[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting Data...\n",
      "Augmented data generated... starting training\n",
      "\n",
      "\n",
      "\n",
      "Epoch 36/100 -- Iteration 216140 - Batch 5580/6016 - Train loss: 15.857144 - Val loss: 0.1192"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m augmentation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     17\u001b[0m use_gpu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m curves, tiempo_ejecucion \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_ones\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mtrain_mnist_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mval_mnist_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43maugmentation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugmentation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mearly_stopping_tolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43muse_gpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_gpu\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pmarc\\Universidad\\inteli\\ZTF_alert_8a\\src\\model\\train.py:145\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_dataset, val_dataset, test_dataset, max_epochs, criterion, batch_size, lr, early_stopping_tolerance, augmentation, use_gpu)\u001b[0m\n\u001b[0;32m    141\u001b[0m     diff \u001b[38;5;241m=\u001b[39m diff\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;66;03m# y_batch = y_batch.cuda()\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# Predicción\u001b[39;00m\n\u001b[1;32m--> 145\u001b[0m reconstruction, mu, logvar, sigma \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdiff\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(reconstruction, diff, mu, logvar, sigma)\u001b[38;5;241m.\u001b[39mmean() \u001b[38;5;241m/\u001b[39m batch_size\n\u001b[0;32m    148\u001b[0m \u001b[38;5;66;03m# Actualización de parámetros\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pmarc\\.conda\\envs\\inteli_gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pmarc\\.conda\\envs\\inteli_gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pmarc\\Universidad\\inteli\\ZTF_alert_8a\\src\\model\\vae.py:102\u001b[0m, in \u001b[0;36mVAE.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    100\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreparametrize(mu, logvar)\n\u001b[0;32m    101\u001b[0m sigma \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_sigma(z)\n\u001b[1;32m--> 102\u001b[0m reconstruction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m reconstruction, mu, logvar, sigma\n",
      "File \u001b[1;32mc:\\Users\\pmarc\\.conda\\envs\\inteli_gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pmarc\\.conda\\envs\\inteli_gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pmarc\\.conda\\envs\\inteli_gpu\\Lib\\site-packages\\torch\\nn\\modules\\container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\pmarc\\.conda\\envs\\inteli_gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pmarc\\.conda\\envs\\inteli_gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pmarc\\.conda\\envs\\inteli_gpu\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:176\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    169\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    171\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[0;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pmarc\\.conda\\envs\\inteli_gpu\\Lib\\site-packages\\torch\\nn\\functional.py:2512\u001b[0m, in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[0;32m   2510\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m-> 2512\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2513\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[0;32m   2514\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import src.model.train as train\n",
    "importlib.reload(train)\n",
    "import src.model.metrics as metrics\n",
    "importlib.reload(metrics)\n",
    "import src.model.vae as vae\n",
    "importlib.reload(vae)\n",
    "\n",
    "model_ones = vae.VAE(latent_dim=30, n_channels=1)\n",
    "\n",
    "max_epochs = 100\n",
    "criterion = vae.loss_function\n",
    "batch_size = 64\n",
    "lr = 1e-4\n",
    "early_stop = 20\n",
    "augmentation = True\n",
    "use_gpu = True\n",
    "\n",
    "curves, tiempo_ejecucion = train.train_model(model_ones,\n",
    "                                            train_mnist_dataset,\n",
    "                                            val_mnist_dataset,\n",
    "                                            [0],\n",
    "                                            max_epochs=max_epochs,\n",
    "                                            criterion=criterion,\n",
    "                                            batch_size=batch_size,\n",
    "                                            lr=lr,\n",
    "                                            augmentation=augmentation,\n",
    "                                            early_stopping_tolerance=early_stop,\n",
    "                                            use_gpu=use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_ones.eval()\n",
    "img = test_mnist_dataset[1][0][0]\n",
    "plt.imshow(img)\n",
    "plt.yticks([])\n",
    "plt.xticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pmarc\\AppData\\Local\\Temp\\ipykernel_26784\\306258681.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  img_tensor = torch.tensor(img).unsqueeze(0).unsqueeze(0)  # Convertir la imagen a tensor\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAALhUlEQVR4nO3dzW/l91XH8XN9/TiOY+epTT0zoSoiVEUp2VAJCRBrJCQWsGDDv8CODX8FElu2rOgCIUVdgRCRoCpPgapIlKRpU0ySmck82DPjp3t/bODDauiI70km5r5e2xkdHV/7+u3fWJozm6ZpKgCoqrVnvQAAnx+iAECIAgAhCgCEKAAQogBAiAIAsf40f2m5XNbR0VHt7e3VbDb7tHcCoNk0TXV8fFyHh4e1tvbk54GnisLR0VHdvHmzbTkAno0PPvigbty48cQ/f6oo7O3tVVXVL9Wv1Xpt9GwGwGfmsi7q7Xor38+f5Kmi8N//ZLReG7U+EwWAK+e//kOjn/QrAL9oBiBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQAiPVnvQDwbM3Wx78NTItFwyaNpulZb3BleVIAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBW+vLa+vXD4RnTzlbDJlXLg92WOaev7AzPuNzt+Vnh/LmeORe7s+EZy42GRapq+Tl6x8zPm+acjV8pO/h+zzJbH520zJl9cn94xuLW7YZNqqbLy5Y5nxVPCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIA8Tk6GfLZW75yMDzj8WHPcZyHr/Z8Km7/4vhBjy9ev9OwSdVX9j9pmXNz5+7wjMeLzYZNqs4arux87+4XGzapun3/uZY553e3h2fMT3te36qej2nrYvx9MLv/oGETR3YAuMJEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgrubltdmsZcxid/xa1NnBvGGTqsdf6PmYbr52e3jG1188atik6uZ2z+W1G5vjcy6mns/T6XJjeMbabNmwSdU/LG60zLl1PP4+WK73vL7V8zaomjf8vDtv+piuGE8KAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgDE1by8Nk0tY9Y/uj8847m1nlNR87Px61dVVR/vfGl4xreuvdqwSdX8tGVMbd0df42bjp3V5c74jMX2+Iyqqo2TnjkHD8dn7L9/Nj6kqraOHrTMmd07Hp6xPD9v2OTq8aQAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABBX88hOl9ufDI/YmPUc2Zktn2+Zs/XateEZs6nnY6qmwzab98ePKs0vGhZpstjqmbP+qOfY1ObJ+Cdq887jhk16juNUVS1PGi4HrShPCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAxGpfXluOX66aPT5rWKRqftIzp5bjl9cu9npOpi1fPm+Zc/7i5vCMzXs9P/9s3u+Y0XMxbX7eM2f94WJ4xuyk5/LatGw619c1ZwV5UgAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIFb68trybPza2drJrGGTqjrYaxlz/NPjV7TefPO9hk2qfu/Gt1rmdPjR5Ystc/7p0WvDM/74H7/RsEnV9r9ttczZf3f8a3j7/fE9qqrq/KJlzHR5OT6j4fvDVeRJAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgVvrIztpWw5GSl3uOt9z/uYOWOV/7+g+HZ7yxf9SwSdWHi/2WOd97fH14xsmi5yDNvctrwzPWt3sOyZwfbLTMOTsYP7IzXet5fWf3m74lLaeeOSvIkwIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCALHSl9dmu+NXtM5uvtCwSdXdr/b0+cb6+fCMd+7daNik6pvvvtky5/xfnx+eMbtsWKSqOg64zc/GZ1RV7TwYv5hWVbX+qOFK2axnl9nWZs+c+fj7aeo5kHfleFIAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAIiVPrKzOHxpeMZHv7DdsEnV7I0HLXP+/q9fH57x8jsNR1eq6vAHpy1zNt77QcucFuvjb5nlS+NHg6qqLg6avvYul8Mzlls930pmOw1XjKrngFad9nz9XjWeFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQAiJW+vHa5N37l6WK3YZGqWl/ruXa2++PZ8Iy9D5oupr3/ccucyw8/Gp4x29xs2KSqFovhEfN5z89i8815y5yOq2nnL/RcTNs+vWiZs7az0zJnFXlSACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgVvry2rQ2fqVs1nMwrZbL8V2qqi5fbBnTYnr0uGnQ+Is8nZ01LNJj2uh52y12N1rmnO+P7zPNer5+l9s9H5Ofdv/vvHYAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCALHSR3a2PjwenvH8e5sNm1R9fGO7Zc7v/uZbwzP+/Fe/2rBJ1Xf/+fWWOa/+1fgBl80Hi4ZNqi725sMzbr3ZdJDmp05b5uxcOxmesfaXB+OLVNXWvZ4jO/OLi5Y5q8iTAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAsdKX1+rW3eERL/zLVsMiVWcHey1zXv3l+8Mz/uDLf9KwSdWt13pemz/6xq8Mz/j3Rwfji1TVtfXz4Rm/9cK7DZtUbcx6rsn9xZ2fHZ7xo7v7DZtUbdx51DJnevS4Zc4q8qQAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABArfWRnOj0dnjH/8a2GTapeeafnU/H73/mN4Rm/88a3xxepqt8++E7LnD+8/vbwjI3ZvGGTqpPl+NfMnz683rBJ1Z/d/vmWOX/33a8Mz/iZ7/ccx1m7da9lzvLiomXOKvKkAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBArPTlteXx8ediRlXV2n982DLn9b/dHZ7xN2svNWxS9e3NX2+ZM33pC8Mzls9tNmzSY/3jBz2DFouWMV87++HwjMXtOw2bVPV8RFVT02uzijwpABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQK3157f+j5cOHz3qFfnc+edYbtLp81gvA/8KTAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCALH+NH9pmqaqqrqsi6rpU90HgE/BZV1U1f98P3+Sp4rC8fFxVVW9XW8NrgXAs3R8fFz7+/tP/PPZ9JOyUVXL5bKOjo5qb2+vZrNZ64IAfPqmaarj4+M6PDystbUn/+bgqaIAwGrwi2YAQhQACFEAIEQBgBAFAEIUAAhRACD+E5oIpvToGyswAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "model_ones.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    img_tensor = torch.tensor(img).unsqueeze(0).unsqueeze(0)  # Convertir la imagen a tensor\n",
    "    reconstructed_img = model_ones(img_tensor)[0].squeeze().detach().numpy()\n",
    "\n",
    "plt.imshow(reconstructed_img)\n",
    "plt.yticks([])\n",
    "plt.xticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_ones.eval()\n",
    "img = test_mnist_dataset[0][0][0]\n",
    "plt.imshow(img)\n",
    "plt.yticks([])\n",
    "plt.xticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32297/1527667916.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  img_tensor = torch.tensor(img).unsqueeze(0).unsqueeze(0)  # Convertir la imagen a tensor\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    img_tensor = torch.tensor(img).unsqueeze(0).unsqueeze(0)  # Convertir la imagen a tensor\n",
    "    reconstructed_img = model_ones(img_tensor)[0].squeeze().detach().numpy()\n",
    "\n",
    "plt.imshow(reconstructed_img)\n",
    "plt.yticks([])\n",
    "plt.xticks([])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inteli_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
